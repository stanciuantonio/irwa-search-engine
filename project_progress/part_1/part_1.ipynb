{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2461e3d8",
   "metadata": {},
   "source": [
    "1. As a first step, you must pre-process the documents. In particular, for the text fields (title,\n",
    "description) you should:\n",
    "● Removing stop words\n",
    "● Tokenization\n",
    "● Removing punctuation marks\n",
    "● Stemming\n",
    "● and... anything else you think it's needed (bonus point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfb2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8cb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66ba8c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total products in dataset: 28080\n",
      "Sample product title: Solid Women Multicolor Track Pants\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../../data/fashion_products_dataset.json'\n",
    "with open(dataset_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(f\"Total products in dataset: {len(data)}\")\n",
    "\n",
    "data_sample_title = data[0]['title']\n",
    "print(f\"Sample product title: {data_sample_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9dda43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document terms: ['solid', 'women', 'multicolor', 'track', 'pant', 'yorker', 'trackpant', 'made', '100', 'rich', 'comb', 'cotton', 'give', 'rich', 'look', 'design', 'comfort', 'skin', 'friendli', 'fabric', 'itch', 'free', 'waistband', 'great', 'year', 'round', 'use', 'proudli', 'made', 'india']\n"
     ]
    }
   ],
   "source": [
    "def build_terms(document):\n",
    "    \"\"\"\n",
    "    Preprocess the document text (title + description) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "\n",
    "    Argument:\n",
    "    document -- a dictionary with 'title' and 'description' keys\n",
    "\n",
    "    Returns:\n",
    "    tokens - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    text = document['title'] + ' ' + document['description']\n",
    "    text = text.lower()\n",
    "    text = ''.join(char if char.isalnum() or char.isspace() else ' ' for char in text)\n",
    "    text = text.split(\" \")\n",
    "    text = [term for term in text if term not in stop_words]\n",
    "    text = [term for term in text if term != '']\n",
    "    text = [stemmer.stem(term) for term in text]\n",
    "    return text\n",
    "\n",
    "sample_document = data[0]\n",
    "sample_terms = build_terms(sample_document)\n",
    "print(f\"Sample document terms: {sample_terms}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irwa_venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
