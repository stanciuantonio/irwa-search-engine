{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2461e3d8",
   "metadata": {},
   "source": [
    "1. As a first step, you must pre-process the documents. In particular, for the text fields (title,\n",
    "description) you should:\n",
    "● Removing stop words\n",
    "● Tokenization\n",
    "● Removing punctuation marks\n",
    "● Stemming\n",
    "● and... anything else you think it's needed (bonus point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dfb2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/antoniostanciu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ba8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../data/fashion_products_dataset.json'\n",
    "with open(dataset_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e284b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_details(details):\n",
    "    \"\"\"\n",
    "    Extracts only the descriptive values from structured product_details.\n",
    "    Example input: [{\"Color\": \"Blue\"}, {\"Material\": \"Cotton\"}]\n",
    "    Output: \"Blue Cotton\"\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    for category in details:\n",
    "        values.extend(v for v in category.values())\n",
    "    return \" \".join(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9dda43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(document):\n",
    "    \"\"\"\n",
    "    Preprocess the document text (title + description + product_details extracted) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "\n",
    "    Argument:\n",
    "    document -- a dictionary with 'title' and 'description' keys\n",
    "\n",
    "    Returns:\n",
    "    tokens - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "    # 1. Stemmer and stop words\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # 2. Text\n",
    "    text = document['title'] + ' ' + document['description'] + ' ' + extract_product_details(document['product_details'])\n",
    "    text = text.lower()\n",
    "    text = ''.join(char if char.isalnum() or char.isspace() else ' ' for char in text)\n",
    "    text = text.split(\" \")\n",
    "    text = [term for term in text if term not in stop_words]\n",
    "    text = [term for term in text if term != '']\n",
    "    text = [stemmer.stem(term) for term in text]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db8e04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata(document):\n",
    "    \"\"\"\n",
    "    Preprocess the document other fields (category, sub_category, brand, seller) removing stop words,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "\n",
    "    Argument:\n",
    "    document -- a dictionary with 'category', 'sub_category', 'brand', 'seller' keys\n",
    "\n",
    "    Returns:\n",
    "    tokens - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "    # 1. Stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # 2. Text\n",
    "    text = document['category'] + ' ' + document['sub_category'] + ' ' + document['brand'] + ' ' + document['seller']\n",
    "    text = text.lower()\n",
    "    text = ''.join(char if char.isalnum() or char.isspace() else ' ' for char in text)\n",
    "    text = text.split(\" \")\n",
    "    text = [term for term in text if term not in stop_words]\n",
    "    text = [term for term in text if term != '']\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd6f4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(document):\n",
    "    \"\"\"\"\"\n",
    "    Process the document\n",
    "    1. Build the tokens of the document\n",
    "    2. Build the metadata tokens of the document\n",
    "    3. Build the original attributes of the document\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Searchable tokens\n",
    "    tokens = build_terms(document)\n",
    "\n",
    "    # 2. Metadata tokens\n",
    "    metadata = build_metadata(document)\n",
    "\n",
    "    # 3. Original attributes\n",
    "    original = {\n",
    "        \"pid\": document[\"pid\"],\n",
    "        \"title\": document[\"title\"],\n",
    "        \"description\": document[\"description\"],\n",
    "        \"brand\": document[\"brand\"],\n",
    "        \"category\": document[\"category\"],\n",
    "        \"sub_category\": document[\"sub_category\"],\n",
    "        \"product_details\": document[\"product_details\"],\n",
    "        \"seller\": document[\"seller\"],\n",
    "        \"out_of_stock\": document[\"out_of_stock\"],\n",
    "        \"selling_price\": document[\"selling_price\"],\n",
    "        \"discount\": document[\"discount\"],\n",
    "        \"actual_price\": document[\"actual_price\"],\n",
    "        \"average_rating\": document[\"average_rating\"],\n",
    "        \"url\": document[\"url\"]\n",
    "    }\n",
    "    return {\n",
    "        \"searchable_text\": tokens,\n",
    "        \"metadata\": metadata,\n",
    "        \"original\": original\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1a62b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus...\n",
      "Total processed products: 28080\n",
      "======================================================================\n",
      "PROCESSED DOCUMENT EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "1. SEARCHABLE TEXT (38 tokens):\n",
      "   First 15 tokens: ['solid', 'women', 'multicolor', 'track', 'pant', 'yorker', 'trackpant', 'made', '100', 'rich', 'comb', 'cotton', 'give', 'rich', 'look']\n",
      "\n",
      "2. METADATA:\n",
      "   ['clothing', 'accessories', 'bottomwear', 'york', 'shyam', 'enterprises']\n",
      "\n",
      "3. ORIGINAL:\n",
      "   PID: TKPFCZ9EA7H5FYZH\n",
      "   Title: Solid Women Multicolor Track Pants\n",
      "   Price: 921\n",
      "   Rating: 3.9\n",
      "   Out of stock: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing corpus...\")\n",
    "preprocessed_data = [preprocess_document(doc) for doc in data]\n",
    "print(f\"Total processed products: {len(preprocessed_data)}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROCESSED DOCUMENT EXAMPLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample = preprocessed_data[0]\n",
    "\n",
    "print(f\"\\n1. SEARCHABLE TEXT ({len(sample[\"searchable_text\"])} tokens):\")\n",
    "print(f\"   First 15 tokens: {sample[\"searchable_text\"][:15]}\")\n",
    "\n",
    "print(f\"\\n2. METADATA:\")\n",
    "print(f\"   {sample[\"metadata\"]}\")\n",
    "\n",
    "print(f\"\\n3. ORIGINAL:\")\n",
    "print(f\"   PID: {sample[\"original\"][\"pid\"]}\")\n",
    "print(f\"   Title: {sample[\"original\"][\"title\"]}\")\n",
    "print(f\"   Price: {sample[\"original\"][\"selling_price\"]}\")\n",
    "print(f\"   Rating: {sample[\"original\"][\"average_rating\"]}\")\n",
    "print(f\"   Out of stock: {sample[\"original\"][\"out_of_stock\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irwa_venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
